'Cmd/Ctrl+Enter' // Triggers `Todo: Toggle Box`
'Alt+Enter' // Triggers `Todo: Toggle Box`
'Alt+D' // Triggers `Todo: Toggle Done`
'Alt+C' // Triggers `Todo: Toggle Cancelled`
'Alt+S' // Triggers `Todo: Toggle Start`
'Cmd/Ctrl+Shift+A' // Triggers  `Todo: Archive`


TODO List:
    ✔ Add another client to Master DB @started(21-07-14 17:39) @done(21-07-14 17:46) @lasted(7m49s)



Issues:
    ☐ How would the program behave if the client generating data function was running when Master requests the information ?
    ☐ Should client still be producing data after Master requests information ?
    ☐ Check every machine that it's connected to Broker then subscribe it.
        Currently we are just using known presets only 1 Master and Max 2 Clients to test.
        What would happen if we wanted 10 clients or 100 clients..
    ☐ Program is working with "band-aid" sleeps.
        If we increase the data size we have to increase the time of sleeps to be able to have time to generate and send all the information.
    ☐ Program is sending the information from the Client to Master through influxDB database.
        Client to send information does a 'SELECT *' and sends everything to Master's Database.
            How can this be improved?
                Send information in batches of 1/4 ?
            Can we even accept that to send the client's data we have to be in the same "network"
                At the moment, both Client and Master DB are connected to the same influxDB Database.
                Even though they are different machines.
                Is this a premise we can accept?
    ☐ Timestamp in Database Problem
        Timestamp value: '2021-07-14T14:11:47.584000Z'
        To be able to view the information in Grafana, every data value has an increase in timestamp to differentiate them.
        Before every 10,000 data values would be only writing at most 500 different data values due to the fact that the timestamp was the same in most of them
        To workaround this timestamp evolves rapidly, making it not give the exact timestamp of the data generated but giving ALL the data generated.
    ☐ Influx 2.0 vs Influx 1.8 vs Flux

    ☐ Issue where we made timestamp jump higher between created welding values because of the amount of high amount of welding_values we tried to insert (250,000)


Questions:
    ☐ When doing Quality Assurance of each Controller with what values we exactly intend to check it's performance:
        At the moment we are generating each client's data randomly (welding_value between 0-30 with 4 decimal cases) e.g.: 15,4567
        Another problem risen from this is the timestamp is being generated random to prevent any timestamp to be repeated making it impossible to write to the database 
        (it only inserts 1 entry if the timestamp is equal, therefore losing welding values).
        We need to try to get Grafana to work with controller's quality.
    ☐ What is the unit value of welding_value ?


Interesting:
    The number of pounds of welding electrodes or welding wire necessary to complete a given weld joint maybe calculated by the formula := P = W.L / E
    Where:=
        P = Pounds of electrode or wire required
        W = Weight per foot of weld metal
        L = Length of weld (feet)
        E = Deposition efficiency
    --------------------------------------------------------------------------------------------------
    https://www.twi-global.com/technical-knowledge/job-knowledge/measurement-of-arc-welding-parameters-139
    -----------
    Hi = A x V x 0.06/s. Welding current A in Amps, Arc voltage V in volts & the welding speed in mm/min are the key elements of this calculation.
    https://prnt.sc/1b3veoh

Grafana Queries:
    SELECT "welding_value" FROM "weldingEvents" WHERE ("client" = 'client1') AND $timeFilter GROUP BY *
    table = SELECT count("welding_value") FROM "weldingEvents" GROUP BY *

Master: 

Client: 
